# Stage 5

from=3, ack=2 (по дефолту)

запускаю 3 инстанса в разных потоках

## PUT TEST

### Сравнение со stage 4

```shell
./wrk -d 30 -t 4 -c 32 -R 15000 -L -s src/main/java/ru/vk/itmo/test/reshetnikovaleksei/lua/put.lua  http://localhost:8080

 Latency |  было  |  стало
 50.000% | 6.29s  |  82.88ms
 75.000% | 7.17s  | 558.59ms
 90.000% | 7.56s  |   1.13s 
 99.000% | 7.82s  |   1.50s 
 99.900% | 7.86s  |   1.62s 
 99.990% | 7.88s  |   1.64s 
 99.999% | 7.89s  |   1.65s 
100.000% | 7.89s  |   1.65s 
```

В среднем производительность увеличилась примерно в 7 раз, благодаря тому, что теперь входящие запросы не ждут 
завершения предыдущих запросов, а отрабатывают параллельно 

### Профилирование

[Allocation profile](put_alloc.html)

В целом картина такая же, как и в stage4, за исключением того, что часть кода приложения теперь исполняется внутри
`ForkJoinWorkerThread`. Здесь испольняются колбеки от `CompletableFuture`. `ForkJoinWorkerThread` занимает 2.21% всех аллокаций

[CPU profile](put_cpu.html)

В целом все также, как и в прошлой лабораторной, помимо того, что `handleRequest` стал занимать меньше процессорного
времени (было 15%, стало 11%), и `ForkJoinWorkerThread` изменился с 7% на 11% (что в целом логично)

[Lock profile](put_lock.html)

Картина осталась такой же

## GET TEST

### Сравнение с stage4

```shell
./wrk -d 30 -t 4 -c 32 -R 15000 -L -s src/main/java/ru/vk/itmo/test/reshetnikovaleksei/lua/get.lua http://localhost:8080

 Latency |  было    |  стало
 50.000% | 436.99ms |  35.46ms
 75.000% | 640.00ms | 107.07ms
 90.000% | 729.09ms | 157.57ms
 99.000% | 997.38ms | 176.77ms
 99.900% |   1.02s  | 184.83ms
 99.990% |   1.03s  | 186.11ms
 99.999% |   1.04s  | 186.75ms
100.000% |   1.04s  | 186.88ms
```

В среднем производительность увеличилась примерно в 9 раз, благодаря тому, что теперь входящие запросы не ждут
завершения предыдущих запросов, а отрабатывают параллельно 

### Профилирование

[Allocation profile](get_alloc.html)

[CPU profile](get_cpu.html)

[Lock profile](get_lock.html)

По числам при `GET` примерно такая же картина, как и `PUT`

## Вывод

Параллельное выполение операций значительно увеличила прозводительность сервера, благодаря тому, что мы больше
не блокируем потоки на ожидание ответа от редиректов, а выполняем их асинхронно. 

Возможные улучшения: думаю, что увеличение кол-ва потоков у воркеров может еще сильнее увеличить производительность,
так как это увеличило бы пропускную способность сервера в целом (чем больше рабочей, тем быстрее все обработается, 
меньше времени ожидания на освобождение потоков)